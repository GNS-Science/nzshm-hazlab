{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from risk_targeted_hazard import *\n",
    "from openquake.baselib.general import BASE183\n",
    "import os\n",
    "\n",
    "%run -i \"C:\\Users\\ahul697\\Desktop\\Research\\GitHub_Repos\\GNS\\nzshm-hazlab\\hdf5_postprocessing\\parse_metadata\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = 'data'\n",
    "\n",
    "oq_id = 32\n",
    "file_id = str(Path(folder,f'calc_{oq_id}.hdf5'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### retrieve hcurves from oq file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = retrieve_data(file_id)\n",
    "vs30 = check_vs30(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### calculate APoE based design intensities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ahul697\\Desktop\\Research\\GitHub_Repos\\GNS\\risk-targeted-hazard\\risk_targeted_hazard\\prepare_design_intensities.py:30: RuntimeWarning: divide by zero encountered in log\n",
      "  im_hazard[i_site,i_imt,:,i_rlz,0] = np.exp(np.interp(np.log(1/hazard_rps), np.log(np.flip(hcurves_rlzs[i_site,i_imt,:,i_rlz])), np.log(np.flip(imtls[imt]))))\n",
      "C:\\Users\\ahul697\\Desktop\\Research\\GitHub_Repos\\GNS\\risk-targeted-hazard\\risk_targeted_hazard\\prepare_design_intensities.py:42: RuntimeWarning: divide by zero encountered in log\n",
      "  stats_im_hazard[i_site,i_imt,:,i_stat] = np.exp(np.interp(np.log(1/hazard_rps), np.log(np.flip(hcurves_stats[i_site,i_imt,:,i_stat])), np.log(np.flip(imtls[imt]))))\n"
     ]
    }
   ],
   "source": [
    "hazard_rps = np.array([25,50,100,250,500,1000,2500])\n",
    "data['hazard_design'] = {}\n",
    "data['hazard_design']['hazard_rps'] = hazard_rps.tolist()\n",
    "\n",
    "for intensity_type in ['acc','disp']:\n",
    "    [im_hazard, stats_im_hazard] = calculate_hazard_design_intensities(data,hazard_rps,intensity_type)\n",
    "\n",
    "    data['hazard_design'][intensity_type] = {}\n",
    "    data['hazard_design'][intensity_type]['im_hazard'] = im_hazard.tolist()\n",
    "    data['hazard_design'][intensity_type]['stats_im_hazard'] = stats_im_hazard.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get the metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ahul697\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1596: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n",
      "C:\\Users\\ahul697\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1745: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(ilocs[0], value)\n",
      "C:\\Users\\ahul697\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1765: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(loc, value)\n"
     ]
    }
   ],
   "source": [
    "source_lt, gsim_lt_dict, rlz_lt = parse_logic_tree_branches(file_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_name = 'test-export'\n",
    "\n",
    "parameters_for_exporting = {}\n",
    "parameters_for_exporting['sites'] = ['Wellington','Christchurch','Dunedin','Auckland']\n",
    "parameters_for_exporting['imts']  = [imt_from_period(period) for period in [0,0.2,0.5,1.0,2.0,3.0,5.0]]\n",
    "parameters_for_exporting['rps']   = [25,50,100,250,500,1000,2500]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = str(Path(export_name,f'{export_name}_postprocessed_vs30-{vs30}.hdf5'))\n",
    "\n",
    "# create the initial file with the metadata\n",
    "with h5py.File(filename,'w') as hf: \n",
    "    grp = hf.create_group('metadata')\n",
    "    # store the intensity measure types and levels for acceleration and displacement-based intensities\n",
    "    for intensity_type in ['acc','disp']:\n",
    "        grp.attrs[f'{intensity_type}_imtls'] = str(data['metadata'][f'{intensity_type}_imtls'])\n",
    "    # store the list of quantiles in the summary statistics\n",
    "    grp.attrs['quantiles'] = data['metadata']['quantiles']\n",
    "    # store the realization weights\n",
    "    grp.attrs['rlz_weights'] = data['metadata']['rlz_weights']\n",
    "    # store the vs30 of all the sites\n",
    "    grp.attrs['vs30'] = vs30\n",
    "    \n",
    "# add sites to metadata\n",
    "pd.DataFrame(data['metadata']['sites']).to_hdf(filename,'metadata/sites','a')\n",
    "\n",
    "# add logic trees to metadata\n",
    "pd.DataFrame(source_lt).to_hdf(filename,'metadata/logic_trees/source_lt','a')\n",
    "pd.DataFrame(rlz_lt).to_hdf(filename,'metadata/logic_trees/full_lt','a')\n",
    "for i,df in gsim_lt_dict.items():\n",
    "    trt = np.unique(df['trt'].values)[0].replace(' ','_')\n",
    "    pd.DataFrame(df).to_hdf(filename,f'metadata/logic_trees/gsim_lts/{trt}','a')\n",
    "    \n",
    "# add hazard curve data\n",
    "with h5py.File(filename,'a') as hf: \n",
    "    grp = hf.create_group('hcurves')\n",
    "    for label in ['hcurves_rlzs','hcurves_stats']:\n",
    "        dset = grp.create_dataset(label,data=np.array(data['hcurves'][label]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_metadata_file(export_name,vs30,rlz_lt,gsim_lt_dict)\n",
    "create_hcurves_single_vs30(export_name,vs30,parameters_for_exporting,data)\n",
    "create_uhs_single_vs30(export_name,vs30,parameters_for_exporting,data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
